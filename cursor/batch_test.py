#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡äº¤æ˜“å»¶è¿Ÿç›‘æ§æµ‹è¯•è„šæœ¬
ç”¨äºè¿è¡Œå¤šæ¬¡æµ‹è¯•å¹¶æ”¶é›†ç»Ÿè®¡æ•°æ®
"""

import os
import time
import json
import statistics
from datetime import datetime
from typing import List, Dict, Any

# å¯¼å…¥é…ç½®
from config import *

class BatchTestRunner:
    """æ‰¹é‡æµ‹è¯•è¿è¡Œå™¨"""

    def __init__(self, test_count: int = 5, interval: int = 30):
        """
        åˆå§‹åŒ–æ‰¹é‡æµ‹è¯•è¿è¡Œå™¨
        
        Args:
            test_count: æµ‹è¯•æ¬¡æ•°
            interval: æµ‹è¯•é—´éš”ï¼ˆç§’ï¼‰
        """
        self.test_count = test_count
        self.interval = interval
        self.results: List[Dict[str, Any]] = []
        self.start_time = None

        print(f"ğŸš€ æ‰¹é‡æµ‹è¯•é…ç½®")
        print(f"ğŸ“Š æµ‹è¯•æ¬¡æ•°: {test_count}")
        print(f"â±ï¸  æµ‹è¯•é—´éš”: {interval} ç§’")
        print(f"ğŸŒ ç½‘ç»œ: {NETWORK}")
        print(f"ğŸ“Š äº¤æ˜“å¯¹: {SYMBOL}")
        print(f"ğŸ“ ç›‘æ§ç›®å½•: {NODE_FILES_DIR}")
        print("=" * 50)

    def run_single_test(self, test_id: int) -> Dict[str, Any]:
        """
        è¿è¡Œå•æ¬¡æµ‹è¯•
        
        Args:
            test_id: æµ‹è¯•ID
            
        Returns:
            æµ‹è¯•ç»“æœå­—å…¸
        """
        print(f"\nğŸ”„ å¼€å§‹ç¬¬ {test_id} æ¬¡æµ‹è¯•")
        print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        # æ¨¡æ‹Ÿæµ‹è¯•è¿‡ç¨‹
        test_start = time.time()

        # æ¨¡æ‹Ÿå‘é€è®¢å•
        print("ğŸ“¤ æ¨¡æ‹Ÿå‘é€è®¢å•...")
        time.sleep(1)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ

        # æ¨¡æ‹Ÿç­‰å¾…æ¥æ”¶
        print("ğŸ“‹ ç­‰å¾…æ¥æ”¶ç¡®è®¤...")
        time.sleep(2)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´

        # è®¡ç®—å»¶è¿Ÿï¼ˆæ¨¡æ‹Ÿï¼‰
        latency = (time.time() - test_start) * 1000
        test_end = time.time()

        # ç”Ÿæˆæµ‹è¯•ç»“æœ
        result = {
            "test_id": test_id,
            "start_time": datetime.fromtimestamp(test_start).isoformat(),
            "end_time": datetime.fromtimestamp(test_end).isoformat(),
            "latency_ms": round(latency, 2),
            "latency_seconds": round(latency / 1000, 3),
            "status": "success" if latency < LATENCY_THRESHOLD else "warning",
            "network": NETWORK,
            "symbol": SYMBOL,
            "side": SIDE,
            "size": SIZE,
            "threshold_ms": LATENCY_THRESHOLD
        }

        # æ˜¾ç¤ºç»“æœ
        if result["status"] == "success":
            print(f"âœ… æµ‹è¯• {test_id} å®Œæˆ - å»¶è¿Ÿ: {result['latency_ms']} æ¯«ç§’")
        else:
            print(f"âš ï¸  æµ‹è¯• {test_id} å®Œæˆ - å»¶è¿Ÿ: {result['latency_ms']} æ¯«ç§’ (è¶…è¿‡é˜ˆå€¼)")

        return result

    def run_batch_tests(self) -> None:
        """è¿è¡Œæ‰¹é‡æµ‹è¯•"""
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡æµ‹è¯•ï¼Œå…± {self.test_count} æ¬¡")
        self.start_time = time.time()

        for i in range(1, self.test_count + 1):
            try:
                result = self.run_single_test(i)
                self.results.append(result)

                # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡æµ‹è¯•ï¼Œç­‰å¾…é—´éš”
                if i < self.test_count:
                    print(f"â³ ç­‰å¾… {self.interval} ç§’åå¼€å§‹ä¸‹æ¬¡æµ‹è¯•...")
                    time.sleep(self.interval)

            except KeyboardInterrupt:
                print(f"\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­æµ‹è¯•ï¼Œå·²å®Œæˆ {i-1} æ¬¡")
                break
            except Exception as e:
                print(f"âŒ æµ‹è¯• {i} å¤±è´¥: {e}")
                error_result = {
                    "test_id": i,
                    "start_time": datetime.now().isoformat(),
                    "end_time": datetime.now().isoformat(),
                    "latency_ms": 0,
                    "latency_seconds": 0,
                    "status": "error",
                    "error": str(e),
                    "network": NETWORK,
                    "symbol": SYMBOL,
                    "side": SIDE,
                    "size": SIZE,
                    "threshold_ms": LATENCY_THRESHOLD
                }
                self.results.append(error_result)

        self.end_time = time.time()
        print(f"\nğŸ æ‰¹é‡æµ‹è¯•å®Œæˆï¼Œå…±è¿è¡Œ {len(self.results)} æ¬¡")

    def generate_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        if not self.results:
            return {"error": "æ²¡æœ‰æµ‹è¯•ç»“æœ"}

        # è¿‡æ»¤æˆåŠŸçš„æµ‹è¯•ç»“æœ
        successful_results = [r for r in self.results if r["status"] == "success"]
        error_results = [r for r in self.results if r["status"] == "error"]
        warning_results = [r for r in self.results if r["status"] == "warning"]

        if successful_results:
            latencies = [r["latency_ms"] for r in successful_results]
            report = {
                "summary": {
                    "total_tests": len(self.results),
                    "successful_tests": len(successful_results),
                    "error_tests": len(error_results),
                    "warning_tests": len(warning_results),
                    "success_rate": round(len(successful_results) / len(self.results) * 100, 2)
                },
                "latency_stats": {
                    "min_ms": min(latencies),
                    "max_ms": max(latencies),
                    "mean_ms": round(statistics.mean(latencies), 2),
                    "median_ms": round(statistics.median(latencies), 2),
                    "std_dev_ms": round(statistics.stdev(latencies), 2) if len(latencies) > 1 else 0
                },
                "threshold_analysis": {
                    "threshold_ms": LATENCY_THRESHOLD,
                    "below_threshold": len([l for l in latencies if l < LATENCY_THRESHOLD]),
                    "above_threshold": len([l for l in latencies if l >= LATENCY_THRESHOLD])
                },
                "test_duration": {
                    "start_time": datetime.fromtimestamp(self.start_time).isoformat() if self.start_time else None,
                    "end_time": datetime.fromtimestamp(self.end_time).isoformat() if self.end_time else None,
                    "total_duration_seconds": round(self.end_time - self.start_time, 2) if self.start_time and self.end_time else 0
                },
                "configuration": {
                    "network": NETWORK,
                    "symbol": SYMBOL,
                    "side": SIDE,
                    "size": SIZE,
                    "monitor_timeout": MONITOR_TIMEOUT,
                    "latency_threshold": LATENCY_THRESHOLD
                },
                "detailed_results": self.results
            }
        else:
            report = {
                "summary": {
                    "total_tests": len(self.results),
                    "successful_tests": 0,
                    "error_tests": len(error_results),
                    "warning_tests": len(warning_results),
                    "success_rate": 0.0
                },
                "error": "æ²¡æœ‰æˆåŠŸçš„æµ‹è¯•ç»“æœ",
                "detailed_results": self.results
            }

        return report

    def print_report(self, report: Dict[str, Any]) -> None:
        """æ‰“å°æµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“Š æ‰¹é‡æµ‹è¯•æŠ¥å‘Š")
        print("=" * 60)

        if "error" in report:
            print(f"âŒ {report['error']}")
            return

        # æ‘˜è¦ä¿¡æ¯
        summary = report["summary"]
        print(f"ğŸ“ˆ æµ‹è¯•æ‘˜è¦:")
        print(f"   æ€»æµ‹è¯•æ¬¡æ•°: {summary['total_tests']}")
        print(f"   æˆåŠŸæ¬¡æ•°: {summary['successful_tests']}")
        print(f"   å¤±è´¥æ¬¡æ•°: {summary['error_tests']}")
        print(f"   è­¦å‘Šæ¬¡æ•°: {summary['warning_tests']}")
        print(f"   æˆåŠŸç‡: {summary['success_rate']}%")

        # å»¶è¿Ÿç»Ÿè®¡
        if "latency_stats" in report:
            stats = report["latency_stats"]
            print(f"\nâ±ï¸  å»¶è¿Ÿç»Ÿè®¡ (æ¯«ç§’):")
            print(f"   æœ€å°å€¼: {stats['min_ms']}")
            print(f"   æœ€å¤§å€¼: {stats['max_ms']}")
            print(f"   å¹³å‡å€¼: {stats['mean_ms']}")
            print(f"   ä¸­ä½æ•°: {stats['median_ms']}")
            print(f"   æ ‡å‡†å·®: {stats['std_dev_ms']}")

        # é˜ˆå€¼åˆ†æ
        if "threshold_analysis" in report:
            threshold = report["threshold_analysis"]
            print(f"\nğŸ¯ é˜ˆå€¼åˆ†æ:")
            print(f"   é˜ˆå€¼: {threshold['threshold_ms']} æ¯«ç§’")
            print(f"   ä½äºé˜ˆå€¼: {threshold['below_threshold']} æ¬¡")
            print(f"   é«˜äºé˜ˆå€¼: {threshold['above_threshold']} æ¬¡")

        # æµ‹è¯•æ—¶é•¿
        if "test_duration" in report:
            duration = report["test_duration"]
            print(f"\nâ° æµ‹è¯•æ—¶é•¿:")
            print(f"   å¼€å§‹æ—¶é—´: {duration['start_time']}")
            print(f"   ç»“æŸæ—¶é—´: {duration['end_time']}")
            print(f"   æ€»è€—æ—¶: {duration['total_duration_seconds']} ç§’")

        # é…ç½®ä¿¡æ¯
        if "configuration" in report:
            config = report["configuration"]
            print(f"\nâš™ï¸  é…ç½®ä¿¡æ¯:")
            print(f"   ç½‘ç»œ: {config['network']}")
            print(f"   äº¤æ˜“å¯¹: {config['symbol']}")
            print(f"   äº¤æ˜“æ–¹å‘: {'ä¹°å…¥' if config['side'] == 'B' else 'å–å‡º'}")
            print(f"   äº¤æ˜“æ•°é‡: {config['size']}")
            print(f"   ç›‘æ§è¶…æ—¶: {config['monitor_timeout']} ç§’")
            print(f"   å»¶è¿Ÿé˜ˆå€¼: {config['latency_threshold']} æ¯«ç§’")

        print("=" * 60)

    def save_results(self, report: Dict[str, Any]) -> None:
        """ä¿å­˜æµ‹è¯•ç»“æœåˆ°æ–‡ä»¶"""
        if SAVE_RESULTS:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"batch_test_results_{timestamp}.json"

            try:
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(report, f, indent=2, ensure_ascii=False)
                print(f"ğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {filename}")
            except Exception as e:
                print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")

    def run(self) -> None:
        """è¿è¡Œå®Œæ•´çš„æ‰¹é‡æµ‹è¯•æµç¨‹"""
        try:
            # è¿è¡Œæ‰¹é‡æµ‹è¯•
            self.run_batch_tests()

            # ç”ŸæˆæŠ¥å‘Š
            report = self.generate_report()

            # æ‰“å°æŠ¥å‘Š
            self.print_report(report)

            # ä¿å­˜ç»“æœ
            self.save_results(report)

        except KeyboardInterrupt:
            print("\nâ¹ï¸  æ‰¹é‡æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"âŒ æ‰¹é‡æµ‹è¯•å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("=== Hyperliquid æ‰¹é‡äº¤æ˜“å»¶è¿Ÿç›‘æ§æµ‹è¯• ===")

    # éªŒè¯é…ç½®
    if not validate_config():
        print("âŒ é…ç½®éªŒè¯å¤±è´¥")
        return

    # æ‰¹é‡æµ‹è¯•å‚æ•°
    TEST_COUNT = 5      # æµ‹è¯•æ¬¡æ•°
    TEST_INTERVAL = 30  # æµ‹è¯•é—´éš”ï¼ˆç§’ï¼‰

    # åˆ›å»ºå¹¶è¿è¡Œæ‰¹é‡æµ‹è¯•
    runner = BatchTestRunner(TEST_COUNT, TEST_INTERVAL)
    runner.run()

if __name__ == "__main__":
    main()
